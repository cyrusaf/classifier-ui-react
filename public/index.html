<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title></title>

    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,400italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
    <link rel="stylesheet" href="/css/main.css" media="screen" charset="utf-8">
  </head>
  <body>
    <section id="splash">
      <h1>Wikipedia Document Classifier</h1>
      <div class="caption">Final Project for Machine Learning (EECS 349)</div>
      <div class="caption">By Cyrus Forbes, Dylan McCann, and Niall Pereira</div>
      <div class="caption">forbescyrus@gmail.com</div>

      <div class="container">
        <div id="classifier"></div>
      </div>
    </section>

    <section>
      <div class="container">

        <h1>Abstract</h1>
        <h2>Motivation</h2>
        <p>
          Document classification has many modern day applications. Google has used document classification successfully
          for spam dectection in Gmail and for language identification in Google Translate. Our goal is to
          use document classifcation to classify a new Wikipedia article under an existing Wikipedia category. This classifier
          could be used to build a knowledge base from Wikipedia or to help file documents in a library. We found the
          biggest challenge of training the classifier to be figuring out what our categories should be, how many categories
          there should be, and which subcategories should fall under each category.
        </p>

        <h2>Methodology</h2>
        <p>
          After collecting the categorized articles from Wikipedia, we trained a multinomial Naive Bayes classifier. We used the Naive
          Bayes implementation from the Python package <a href="http://scikit-learn.org/stable/modules/naive_bayes.html">sklearn</a>,
          and we used <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html">Pandas dataframes</a>
          to manipulate the dataset. We can pass in a string of text to our Naive Bayes classifier and it will return the category
          that has the highest probability of containing the passed in text.
        </p>

        <h2>Testing and Training Data</h2>
        <p>
          The bulk of our work was the data collection process. Since there are thousands of documents that we needed to retrieve
          from Wikipedia, we had to create a efficient and concurrent retreival method. We also had to tweak the structure of the
          dataset for the best results. We were presented with a couple questions. <i>What should the categories be? How do we know if
          a category is performing well?</i> We used <a href="https://en.wikipedia.org/wiki/Portal:Contents/Categories">Wikipedia's categories</a> to
          provide a basis of where to start. We ended up with just over 15,000 documents in our dataset of 14 categories. We used
          10-fold validation to test our dataset, and calculated the precision and recall of each category.
        </p>

        <h2>Results</h2>
        <p>
          We used 10 fold validation to test our Naive Bayes classifier. 1/10th of the dataset was randomly choosen to be the testing
          data, while the other 9/10ths were used for training. We confirmed that Wikipedia articles work as training data for an accurate classifier.
          We can also see that certain categories perform very differently. <i>Why do some categories perform so poorly in recall and so well in precision?</i>
          The answers to these questions could provide the answer to finding the optimal set of categories. <i>How can we change a category so that
          its recall and precision improve?</i> We will touch on these questions in the results section of the detailed report.
        </p>
        <br>

        <div id="results_chart"></div>

        <h1>Detailed Report</h1>
        <h2>Introduction</h2>
        <p>
          Our task is to predict the category that a body of text belongs to. We use <a href="https://en.wikipedia.org/wiki/Portal:Contents/Categories">Wikipedia’s
          list of categories</a> to define our outputs - and the body of each article (under a category) as
          the training data for the outputs. Our has mainly focused on retrieving the data from wikipedia in
          a timely manner. We will first talk about our methodology of retrieving the data, then we will
          talk about how we structured the data, and finally we will discuss our results.
        </p>

        <h2>Retrieving the Data</h2>
        <p>
          In order to retrieve the data we had to scrape 50,000+ articles from wikipedia. Originally we were using
          500,000+ articles (for 500+ categories), but we did not see great results with so many categories, so we
          reduced the number of categories to 14. If we scraped the articles one by one and each http request
          took 0.2 seconds on average (a low estimate), it would take 3 hours to scrape all the pages. We managed to
          scrape all pages in less than 1 minute by taking advantage of Golang’s concurrency features.
        </p>
        <p>
          Without going into too much detail, we have a seperate thread for each category, which scrapes the articles one
          by one in each category. This means that we can have many http requests going at once so that no time is wasted
          waiting for the http responses. We ran into an issue with having too many threads making requests would cause an
          error (due to too many concurrent http requests at once), so we modified the code to restrict the total number of
          threads to a number where the code ran smoothly. We stored all the data in a hierarchy of folders where
          each folder is named after a category and within each folder are documents containing the body of the wikipedia
          articles in that category (see Figure 1).
        </p>

        <img src="img/folders.png" alt="Figure 1: Scraped Categories from Wikipedia (text files inside each folder)" />
        <div class="figure_caption"><span>Figure 1:</span> Scraped Categories from Wikipedia (text files inside each folder)</div>

        <h2>Transforming the Data</h2>
        <p>
          We defined our categories in a YAML file (see Figure 2). The YAML file contained category names and a list of
          Wikipedia links to subcategory pages. Each <a href="https://en.wikipedia.org/wiki/Category:Medicine">subcategory page</a> contains many links to Wikipedia
          documents - which our Golang script will retrieve and store on the hard drive.
        </p>
        <img src="img/yaml.png" alt="Figure 2: YAML Configuration File" />
        <div class="figure_caption"><span>Figure 2:</span> YAML Configuration File</div>

        <p>
          Originally we used every single subcategory on wikipedia as a category (500+), but this caused our classifier to be highly
          inaccurate. We switched over to using the YAML configuration file so we could define our own custom categories and consolidate
          many subcategories within a single category.
        </p>

        <h2>The Classifier</h2>
        <p>
          Since we used sklearn’s Naive Bayes classifier, there is not too much to discuss when it comes to implementation. Sklearn’s
          Naive Bayes is a multinomial classifier, so it takes multiple instances of a word into account. We used Panda’s dataframes to store
          and manipulate the data - such as randomly ordering it for 10-fold classification. We used <a href="https://docs.python.org/3/library/pickle.html">
          Python's pickle library</a> to serialize the classifier and save it so we did not have to retrain it repeatedly.
        </p>

        <h2>Results and Future Work</h2>
        <p>
          Our results show that Wikipedia articles are excellent training data for a classifier. To go back to our questions posed in the results
          section of the abstract: <i>Why do some categories perform so poorly in recall and so well in precision?
          How can we change a category so that its recall and precision improve?</i> A low recall value means that many documents are being classified incorrectly
          as that category. Thus to improve the recall value, we should make the category more specific by seperating it out into more specific categories
          (eg. [physical sciences] -> [physics, chemistry, astronomy, ...]). If a precision value is low, that means the category is not being able to identify articles
          that belong to it. Thus, we should make the category more broad and maybe even consilidate other alike categories with it
          (eg. [physics, chemistry, astronomy, ...] -> [physical sciences]).
        </p>
        <br>

        <div id="results_chart2"></div>

        <p>
          Our categories, being manually defined, are not the optimal categories. Future work should include finding a balance between number
          of categories and accuracy. Figuring out what the categories should be is a difficult question. It can be done through trial and
          error manually, but that would take a very long time and require a lot of human input. It would be a good idea to develop an easy way
          to manipulate the categories and graph the results (in a webapp?). Another way would be to use a genetic
          algorithm to maximize classifier accuracy and number of categories. The genes would represent the categories and the subcategories
          within each category.  Another method might be through unsupervised learning to group the documents into categories.
        </p>
      </div>
    </section>


    <script type="text/javascript" src="js/bundle.js"></script>
  </body>
</html>
